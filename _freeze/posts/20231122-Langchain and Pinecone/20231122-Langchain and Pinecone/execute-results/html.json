{
  "hash": "11318a9df1c84e45e15ff4ec26e46e94",
  "result": {
    "markdown": "---\ntitle: \"Using Vector Store Database\"\ndescription: \"An example using pinecone and langchain\"\nauthor: \"Luke Heley\"\ndate: \"22 Nov 23\"\nfreeze: true\nexecute:\n  eval: true\nformat:\n  html:\n    toc: true\n    code-fold: show\ncategories:\n - large language models (LLM)\n - evidence synthesis\n - methods\n - notes\neditor_options:\n  chunk_output_type: console\n---\n\n# Introduction\n\nhttps://docs.pinecone.io/docs/langchain\n\n# Build the Knowledge Base\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport sys\n\nfrom langchain.document_loaders import PyPDFLoader\nf = open(\"sources.txt\", \"r\")\nurls = f.readlines()\nf.close()\n\nnewurls = []\nfor url in urls:\n  newurls.append(url.replace(\"\\n\", \"\"))\n\nurls = newurls\ndocuments = []\nfor url in urls:\n  print(url)\n  documents.extend(PyPDFLoader(url).load())\n\nprint(\"documents:\", len(urls))\nprint(\"pages:\", len(documents))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhttps://www.nao.org.uk/wp-content/uploads/2000/11/9900970es.pdf\nhttps://www.nao.org.uk/wp-content/uploads/2000/11/9900970.pdf\nhttps://www.nao.org.uk/wp-content/uploads/2000/11/n9900970app3.pdf\nhttps://www.nao.org.uk/wp-content/uploads/2005/11/0506595_I.pdf\nhttps://www.nao.org.uk/wp-content/uploads/2005/11/0506595_I1.pdf\nhttps://www.nao.org.uk/wp-content/uploads/2005/11/0506595_II.pdf\ndocuments: 6\npages: 443\n```\n:::\n:::\n\n\nDocuments are split by pages which contain a lot of text. Our first task is therefore to identify a good preprocessing method for chunking these articles into \"concise\" chunks to later be embedded and stored into the pinecone database.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport tiktoken\n\ntiktoken.encoding_for_model('gpt-3.5-turbo')\ntokenizer = tiktoken.get_encoding('cl100k_base')\n\n# create the length function\ndef tiktoken_len(text):\n    tokens = tokenizer.encode(\n        text,\n        disallowed_special=()\n    )\n    return len(tokens)\n\ntiktoken_len(\"hello I am a chunk of text and using the tiktoken_len function \"\n             \"we can find the length of this chunk of text in tokens\")\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n26\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=400,\n    chunk_overlap=20,\n    length_function=tiktoken_len,\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)\n\ndocs = text_splitter.split_documents(documents)\n\nprint(\"Length of pages: \", len(documents))\nprint(\"Length of splits: \", len(docs))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLength of pages:  443\nLength of splits:  1078\n```\n:::\n:::\n\n\n# Create Embeddings\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nmodel_name = 'text-embedding-ada-002'\n\nembed = OpenAIEmbeddings(\n    model=model_name,\n    openai_api_key=os.getenv('OPENAI_API_KEY') \n)\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ntexts = [\n    'this is the first chunk of text',\n    'then another second chunk of text is here'\n]\n\nres = embed.embed_documents(texts)\nlen(res), len(res[0])\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(2, 1536)\n```\n:::\n:::\n\n\n# Vector Database\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nimport pinecone\n\nindex_name = 'langchain-retrieval-augmentation'\npinecone.init(\n    api_key=os.getenv(\"PINECONE_API_KEY\"),\n    environment=\"gcp-starter\"\n)\n\nif index_name not in pinecone.list_indexes():\n    # we create a new index\n    pinecone.create_index(\n        name=index_name,\n        metric='cosine',\n        dimension=len(res[0])  # 1536 dim of text-embedding-ada-002\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\lukeh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n```\n:::\n:::\n\n\nConnect to the new index\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nindex = pinecone.GRPCIndex(index_name)\nindex.describe_index_stats()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n{'dimension': 1536,\n 'index_fullness': 0.01078,\n 'namespaces': {'': {'vector_count': 1078}},\n 'total_vector_count': 1078}\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom tqdm.auto import tqdm\nfrom uuid import uuid4\n\nbatch_limit = 100\n\ntexts = []\nmetadatas = []\n\nfor i, record in enumerate(tqdm(documents)):\n    # first get metadata fields for this record\n    metadata = record.metadata\n    # now we create chunks from the record text\n    record_texts = text_splitter.split_text(record.page_content)\n    # create individual metadata dicts for each chunk\n    record_metadatas = [{\n        \"chunk\": j, \"text\": text, **metadata\n    } for j, text in enumerate(record_texts)]\n    # append these to current batches\n    texts.extend(record_texts)\n    metadatas.extend(record_metadatas)\n    # if we have reached the batch_limit we can add texts\n    if len(texts) >= batch_limit:\n        ids = [str(uuid4()) for _ in range(len(texts))]\n        embeds = embed.embed_documents(texts)\n        index.upsert(vectors=zip(ids, embeds, metadatas))\n        texts = []\n        metadatas = []\n\nif len(texts) > 0:\n    ids = [str(uuid4()) for _ in range(len(texts))]\n    embeds = embed.embed_documents(texts)\n    index.upsert(vectors=zip(ids, embeds, metadatas))\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"341f7c1139f549e29579686a8f566895\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nindex.describe_index_stats()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n{'dimension': 1536,\n 'index_fullness': 0.01785,\n 'namespaces': {'': {'vector_count': 1785}},\n 'total_vector_count': 1785}\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom langchain.vectorstores import Pinecone\n\ntext_field = \"text\"\n\n# switch back to normal index for langchain\nindex = pinecone.Index(index_name)\n\nvectorstore = Pinecone(\n    index, embed.embed_query, text_field\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\lukeh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:59: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n  warnings.warn(\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nquery = \"Provide an example of a major project\"\n\nvectorstore.similarity_search(\n    query,  # our search query\n    k=3  # return 3 most relevant docs\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n[Document(page_content='executive summary\\nMAjOR PROjECTS REPORT 2005 5', metadata={'chunk': 0.0, 'page': 10.0, 'source': 'https://www.nao.org.uk/wp-content/uploads/2005/11/0506595_I1.pdf'}),\n Document(page_content='executive summary\\nMAjOR PROjECTS REPORT 2005 5', metadata={'chunk': 0.0, 'page': 10.0, 'source': 'https://www.nao.org.uk/wp-content/uploads/2005/11/0506595_I.pdf'}),\n Document(page_content='2Major Projects Report 2005 Summary of Post-Main Gate projects\\nSource: National Audit Office In-year change  In-year change In-year change  Current Forecast  Budgeted Costs Current  Expected\\non costs to  on in-service on Key User  Costs to  to completion at  Forecast In-service date\\nProject completion  date  Requirements completion  Approval  In-service date  at Approval\\nDescription (£ millions) (months) (£ millions) (£ millions)\\nA400M Heavy transport aircraft +25 0 No change 2644 2628 March 2011 February 2009\\nAirborne Stand-Off Long-range surveillance -14 +12 No change 954 914 November 2006 June 2005\\nRadar (ASTOR) and targeting system\\nAstute Class Attack submarine +8 0 No change 3492 2578 January 2009 June 2005\\nSubmarine\\nBowman Data and voice 16 Met in-service date No change 2007 1898 March 2004 March 2004\\ncommunication radios March 2004\\nBeyond Visual Range Air-to-Air missile -151 0 No change 1204 1240 August 2012 September 2011\\nAir-to-Air Missile (BVRAAM), alsoknown as Meteor\\nC Vehicle Capability Vehicle fleet +36 +3 No change 710 674 March 2006 October 2005\\nComBAT, DBL Bowman-related software, -2 +17 No change 338 343 December 2005 March 2004\\nInfrastructure & Platform hardware and integrationBISA (CIP) systems and tools\\nFuture Joint Combat Fighter/ attack aircraft -659 In-service date No change 1914 2034 In-service date In-service date\\nAircraft (FJCA) not yet approved  not yet approved not yet approved', metadata={'chunk': 0.0, 'page': 14.0, 'source': 'https://www.nao.org.uk/wp-content/uploads/2005/11/0506595_I1.pdf'})]\n```\n:::\n:::\n\n\n# Generative Question Answering\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import RetrievalQA\n\n# completion llm\nllm = ChatOpenAI(\n    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n    model_name='gpt-3.5-turbo',\n    temperature=0.0\n)\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=vectorstore.as_retriever()\n)\n```\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nqa.run(query)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n'One example of a major project mentioned in the provided context is the A400M Heavy transport aircraft.'\n```\n:::\n:::\n\n\nWe can also include the sources of information that the LLM is using to answer our question. We can do this using a slightly different version of `RetrievalQA` called `RetrievalQAWithSourcesChain`:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfrom langchain.chains import RetrievalQAWithSourcesChain\n\nqa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=vectorstore.as_retriever()\n)\n\nqa_with_sources(query)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n{'question': 'Provide an example of a major project',\n 'answer': 'An example of a major project is the A400M Heavy transport aircraft. \\n',\n 'sources': 'National Audit Office In-year change'}\n```\n:::\n:::\n\n\n",
    "supporting": [
      "20231122-Langchain and Pinecone_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"341f7c1139f549e29579686a8f566895\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_6e10cc64f54c4223b0fdbd3a6e5e9b9a\",\"IPY_MODEL_4bae54bea5a94813b6c27420a38f292c\",\"IPY_MODEL_b63d34765f68463893857f32db2cb4b9\"],\"layout\":\"IPY_MODEL_6abd82534f034ea38b3819c7782db9cb\",\"tabbable\":null,\"tooltip\":null}},\"4bae54bea5a94813b6c27420a38f292c\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_d6561179a4ba4258af227dacc8eb5f81\",\"max\":443,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_83986cfb6d9e49d6a5fb018523e62dec\",\"tabbable\":null,\"tooltip\":null,\"value\":443}},\"6abd82534f034ea38b3819c7782db9cb\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"6e10cc64f54c4223b0fdbd3a6e5e9b9a\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_a11f8ff125b34fcb8a9a04941cb4c8db\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_aa53c201ee56497983fe2605dfe4009f\",\"tabbable\":null,\"tooltip\":null,\"value\":\"100%\"}},\"7408b9c141f4456a977b833d7cfb7624\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"83986cfb6d9e49d6a5fb018523e62dec\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}},\"a11f8ff125b34fcb8a9a04941cb4c8db\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"a2f5c3165b21438da2b0ba9e1f70e26d\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"aa53c201ee56497983fe2605dfe4009f\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"b63d34765f68463893857f32db2cb4b9\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_a2f5c3165b21438da2b0ba9e1f70e26d\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_7408b9c141f4456a977b833d7cfb7624\",\"tabbable\":null,\"tooltip\":null,\"value\":\" 443/443 [00:28&lt;00:00, 11.98it/s]\"}},\"d6561179a4ba4258af227dacc8eb5f81\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}