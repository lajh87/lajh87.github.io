{
  "hash": "99d353a926bc2eb68ef90ba256953b45",
  "result": {
    "markdown": "---\ntitle: \"Retrieval Augmented Generation\"\ndescription: \"An applied example using llama index\"\nauthor: \"Luke Heley\"\ndate: \"19 Nov 23\"\nfreeze: true\nexecute:\n  eval: true\nformat:\n  html:\n    toc: true\n    code-fold: show\ncategories:\n - large language models (LLM)\n - evidence synthesis\n - methods\n - notes\neditor_options:\n  chunk_output_type: console\nbibliography: references.bib\n---\n\n# Introduction\n\nThis examples shows how to load data from a pdf, create emeddings, and then query the data.\n\n# Load PDF\n\nWe load the major projects report 2015 into python using (`smart_pdf_loader`)\\[https://llamahub.ai/l/smart_pdf_loader\\].\n\n> SmartPDFLoader is a super fast PDF reader that understands the layout structure of PDFs such as nested sections, nested lists, paragraphs and tables. It uses layout information to smartly chunk PDFs into optimal short contexts for LLMs.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom llama_hub.smart_pdf_loader import SmartPDFLoader\n\nllmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\npdf_url = \"https://www.nao.org.uk/wp-content/uploads/2015/10/Major-Projects-Report-2015-and-the-Equipment-Plan-2015-2025.pdf\" # also allowed is a file path e.g. /home/downloads/xyz.pdf\n\npdf_loader = SmartPDFLoader(llmsherpa_api_url=llmsherpa_api_url)\ndocuments = pdf_loader.load_data(pdf_url)\ndocuments[0:2] # look at first 3 chunks \n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n[Document(id_='7adbabd4-1df8-4ea6-a5cb-ff56f550e0c6', embedding=None, metadata={'chunk_type': 'para'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='7b2a550370ad85d6de2541a641003a5b2971d0115121e67f6ff2a3183be0b7c8', text='Report\\nby the Comptroller and Auditor General', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n Document(id_='3762c995-6cbd-4f15-9e16-491bcc9f1dad', embedding=None, metadata={'chunk_type': 'list_item'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='bb8a396323dd4d9c61c79ed4882caa34151071ed1e48e554c8da9f00a2491810', text='Major Projects Report 2015 and the Equipment Plan 2015 to 2025\\nHC 488-I', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n```\n:::\n:::\n\n\n# Create a Vector Store Index\n\nThe documentation on [VectorStoreIndex](https://gpt-index.readthedocs.io/en/v0.6.8/reference/indices/vector_store.html) feels a little light. My understanding (not least through reference to OpenAI billing) is that this step uses OpenAI `ada` model for embeddings and then stores the index.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom llama_index import VectorStoreIndex\nindex = VectorStoreIndex.from_documents(documents)\nindex\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n<llama_index.indices.vector_store.base.VectorStoreIndex at 0x233c568edc0>\n```\n:::\n:::\n\n\n# Query\n\nWe then use GPT 3.5 is used to query the data.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"Summarise this document.\")\nprint(response)\nresponse = query_engine.query(\"what are the main causes of schedule variation?\")\nprint(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe document is titled \"Major Projects Report 2015 and the Equipment Plan 2015 to 2025.\" It contains an executive project summary and an overview of cost, time, and performance. The report discusses the Department's ability to fund the Equipment Plan and suggests that the Affordability Statement should provide clearer information about uncertainties in costs and the range of possible cost outcomes. It also mentions the need to quantify risks not included in cost forecasts. The document is printed on Evolution Digital Satin paper, which is sourced from responsibly managed and sustainable forests certified by the FSC.\nThe main causes of schedule variation are the net 52-month deferment of the final stage of the Core Production Capability project and the net variation of 8 months in the remaining projects.\n```\n:::\n:::\n\n\n# Next Steps\n\n1.  Being able to search over multiple documents\n2.  Being able to cite sources.\n\n",
    "supporting": [
      "20231119-Retrieval Augmented Generation_files"
    ],
    "filters": [],
    "includes": {}
  }
}